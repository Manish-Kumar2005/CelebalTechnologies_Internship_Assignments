# Model-Evaluation-and-Hyperparameter-Tuning
Train multiple machine learning models and evaluate their performance using metrics such as accuracy, precision, recall, and F1-score. Implement hyperparameter tuning techniques like GridSearchCV and RandomizedSearchCV to optimize model parameters. Analyze the results to select the best-performing model.

Resources :
https://www.kdnuggets.com/hyperparameter-tuning-gridsearchcv-and-randomizedsearchcv-explained

**Multiple models which has been trained are:**
1) Logistic Regression
2) Decision Tree
3) Random Forest
4) SVM (Support Vector Machine)
5) KNN (K-Nearest Neighbors)

 ** Features**
**Model Evaluation:**
1) Accuracy, Precision, Recall, F1-Score
2) Classification Reports
3) Confusion Matrices

 **Hyperparameter Tuning:**
1) Exhaustive search with GridSearchCV (Random Forest)
2) Randomized search with RandomizedSearchCV (SVM)

 **Visualization:**
1) Interactive plots (Matplotlib/Seaborn)
2) Model performance comparison bar charts

**Technologies Used**
Python 3.x

**Libraries:**
scikit-learn (Models, Metrics, Tuning),
pandas (Data Handling),
numpy (Numerical Operations),
matplotlib/seaborn (Visualizations)

